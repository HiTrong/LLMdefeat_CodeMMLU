{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97436,"databundleVersionId":11597044,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing packages","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install \"torch==2.4.0\" \"xformers==0.0.27.post2\" triton torchvision torchaudio \"trl==0.14.0\"\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip uninstall -y trl\n!pip install git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:13:28.338989Z","iopub.execute_input":"2025-03-28T10:13:28.339206Z","iopub.status.idle":"2025-03-28T10:17:20.919860Z","shell.execute_reply.started":"2025-03-28T10:13:28.339184Z","shell.execute_reply":"2025-03-28T10:17:20.918882Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import Libs","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn.functional as F\nfrom unsloth import FastLanguageModel\nfrom datasets import Dataset\n\nimport os\nimport ast\nimport string\nimport random\nfrom tqdm.auto import tqdm\nfrom IPython.display import clear_output\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:17:20.920692Z","iopub.execute_input":"2025-03-28T10:17:20.920957Z","iopub.status.idle":"2025-03-28T10:17:49.224816Z","shell.execute_reply.started":"2025-03-28T10:17:20.920935Z","shell.execute_reply":"2025-03-28T10:17:49.224101Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Downloading model","metadata":{}},{"cell_type":"code","source":"model_name = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n\n# >>> Download LLM Model\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = model_name,\n    max_seq_length = 8192,\n    dtype = None,\n    load_in_4bit = True,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)\n\n# FastLanguageModel.for_inference(model)\n# print(\"Model is ready to inference","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:17:49.225533Z","iopub.execute_input":"2025-03-28T10:17:49.225726Z","iopub.status.idle":"2025-03-28T10:18:19.762868Z","shell.execute_reply.started":"2025-03-28T10:17:49.225709Z","shell.execute_reply":"2025-03-28T10:18:19.761860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:19.763724Z","iopub.execute_input":"2025-03-28T10:18:19.764030Z","iopub.status.idle":"2025-03-28T10:18:26.530754Z","shell.execute_reply.started":"2025-03-28T10:18:19.764001Z","shell.execute_reply":"2025-03-28T10:18:26.529864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load & process dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/fpt-ai-residency-batch-6-entry-test/b6_train_data.csv\")\ndf_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.531725Z","iopub.execute_input":"2025-03-28T10:18:26.531999Z","iopub.status.idle":"2025-03-28T10:18:26.628260Z","shell.execute_reply.started":"2025-03-28T10:18:26.531978Z","shell.execute_reply":"2025-03-28T10:18:26.627454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/fpt-ai-residency-batch-6-entry-test/b6_test_data.csv\")\ndf_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.630031Z","iopub.execute_input":"2025-03-28T10:18:26.630243Z","iopub.status.idle":"2025-03-28T10:18:26.667046Z","shell.execute_reply.started":"2025-03-28T10:18:26.630225Z","shell.execute_reply":"2025-03-28T10:18:26.666213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.668144Z","iopub.execute_input":"2025-03-28T10:18:26.668432Z","iopub.status.idle":"2025-03-28T10:18:26.699458Z","shell.execute_reply.started":"2025-03-28T10:18:26.668411Z","shell.execute_reply":"2025-03-28T10:18:26.698700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = df_train.dropna()\ndf_train = df_train.drop_duplicates()\ndf_train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.700158Z","iopub.execute_input":"2025-03-28T10:18:26.700413Z","iopub.status.idle":"2025-03-28T10:18:26.730749Z","shell.execute_reply.started":"2025-03-28T10:18:26.700393Z","shell.execute_reply":"2025-03-28T10:18:26.729866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.731822Z","iopub.execute_input":"2025-03-28T10:18:26.732160Z","iopub.status.idle":"2025-03-28T10:18:26.747354Z","shell.execute_reply.started":"2025-03-28T10:18:26.732128Z","shell.execute_reply":"2025-03-28T10:18:26.746491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"index2choice = {i: letter for i, letter in enumerate(string.ascii_uppercase)}\nchoice2index = {letter: i for i, letter in enumerate(string.ascii_uppercase)}\n\ndef choices2str(choices):\n    choices_lst = ast.literal_eval(choices)\n    result = \"\"\n    for i in range(0, len(choices_lst)):\n        result = result + index2choice[i] + \". \" + str(choices_lst[i]) + \"\\n\\n\"\n    return result.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.748422Z","iopub.execute_input":"2025-03-28T10:18:26.748714Z","iopub.status.idle":"2025-03-28T10:18:26.753431Z","shell.execute_reply.started":"2025-03-28T10:18:26.748694Z","shell.execute_reply":"2025-03-28T10:18:26.752558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_template = \"\"\"You are a programming expert and will answer multiple-choice questions about code.  \nRead the following code snippet carefully and select the **best** answer.  \n\n### Response Format:\n- Reply with **only** the letter of the correct choice (A, B, C, or D).  \n- Do **not** provide explanations.  \n\n### Question:\n{}\n\n### Choices:\n{}\n\n### Response:\n{}\"\"\"\n\ndef preprocessing(df):\n    df[\"text\"] = df.apply(\n        lambda row: prompt_template.format(\n            row[\"question\"], choices2str(row[\"choices\"]), row[\"answer\"]\n        ), axis=1\n    )\n    return Dataset.from_pandas(df[[\"text\"]])  # Chuyển DataFrame thành Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.754319Z","iopub.execute_input":"2025-03-28T10:18:26.754558Z","iopub.status.idle":"2025-03-28T10:18:26.767424Z","shell.execute_reply.started":"2025-03-28T10:18:26.754529Z","shell.execute_reply":"2025-03-28T10:18:26.766636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = preprocessing(df_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.768135Z","iopub.execute_input":"2025-03-28T10:18:26.768416Z","iopub.status.idle":"2025-03-28T10:18:26.927243Z","shell.execute_reply.started":"2025-03-28T10:18:26.768386Z","shell.execute_reply":"2025-03-28T10:18:26.926330Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = 8092,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 8,\n        gradient_accumulation_steps = 4, \n        warmup_steps = 5,\n        num_train_epochs = 1, # Set this for 1 full training run.\n        # max_steps = 60,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 30,\n        \n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\", # Use this for WandB etc\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:26.928183Z","iopub.execute_input":"2025-03-28T10:18:26.928428Z","iopub.status.idle":"2025-03-28T10:18:29.533166Z","shell.execute_reply.started":"2025-03-28T10:18:26.928408Z","shell.execute_reply":"2025-03-28T10:18:29.532219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:18:29.534036Z","iopub.execute_input":"2025-03-28T10:18:29.534267Z","execution_failed":"2025-03-28T10:33:34.211Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save model","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"lora_model\")  # Local saving\ntokenizer.save_pretrained(\"lora_model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}